{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.ops\n",
    "본 노트에서는 [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882) 논문을 예시로 활용하여, 딥러닝 모형 구현을 위한 각종 연산들을 모듈화하는 방법에 대해서 다룹니다. 전체 딥러닝 모형을 구현하기 위해 필요한 연산들은 따로 하나의 script (eg. `ops.py`)에 모아놓는 것이 좋습니다.  이렇게 하나의 script에 모아놓은 snippet은 전체 딥러닝 모형을 구현하는 script (eg. `net.py`)에서 활용합니다. 이때 필요한 연산을 선정하여 구현하는 기준은 대략적으로 아래처럼 생각해 볼 수 있습니다.\n",
    "\n",
    "1. DeepLearning framework에서 제공하지 않을 경우 (이미 있는 것을 구현하지 말 것)\n",
    "2. DeepLearning framework에서 이미 제공하지만 무언가 기능이 필요할 경우 \n",
    "3. 전체 딥러닝 모형을 정리하는 script에서 코드가 간결해 질 수 있도록 (보기쉬운 코드가 좋은 코드)\n",
    "\n",
    "\n",
    "상기된 논문의 구조는 대략적으로 아래와 같습니다. 이를 보아 대략적으로 아래와 같은 연산들만 구현하여 모듈화를 하면 코드가 간결해 질 것 입니다.\n",
    "\n",
    "* `ops.py`: `MultiChannelEmbedding` class, `ConvolutionLayer` class, `MaxOverTimepooling` class\n",
    "* `net.py`: `SenCNN` class\n",
    "![Alt text](https://raw.githubusercontent.com/aisolab/strnlp/master/materials/img/sencnn_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation tips\n",
    "**위와 같은 연산을 가장 쉽게 구현하는 방법 중 하나는 예제데이터를 미리 생각해놓고 확인하면서 구현하는 것입니다.** 딥러닝 모형 학습 시 대게 미니배치를 이용하여 학습하므로, 우리는 구현해야할 연산이 가장 간단한 미니배치(eg. 미니배치 사이즈가 2인 경우)를 상정하고 각각의 연산을 구현합니다. 이를 위해서 `model.data.ipynb` 노트에서 활용했던 코드들을 가져와서 가장 간단한 미니배치를 구성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Corpus` class의 instance 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/root/Documents/archive/strnlp/exercise/data/.DS_Store'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/train.txt'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/morphs_vec.pkl'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/validation.txt'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/tokenizer.pkl'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/test.txt'),\n",
      " PosixPath('/root/Documents/archive/strnlp/exercise/data/vocab.pkl')]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from mecab import MeCab\n",
    "from torch.utils.data import DataLoader\n",
    "from model.data import Corpus\n",
    "from model.utils import Vocab, Tokenizer, PadSequence\n",
    "\n",
    "data_dir = Path.cwd() / 'data'\n",
    "list_of_dataset = list(data_dir.iterdir())\n",
    "pprint(list_of_dataset)\n",
    "with open(list_of_dataset[-1], mode='rb') as io:\n",
    "    vocab = pickle.load(io)\n",
    "\n",
    "pad_sequence = PadSequence(length=32, pad_val=vocab.to_indices(vocab.padding_token))\n",
    "split_morphs = MeCab().morphs\n",
    "tokenizer = Tokenizer(vocab, split_fn=split_morphs, pad_fn=pad_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_corpus = Corpus(list_of_dataset[1], transform_fn=tokenizer.split_and_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DataLoader` class의 instance를 이용, 가장 간단한 미니배치 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dl = DataLoader(tr_corpus, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[3070, 2750, 3116, 3109, 2750, 2084,  782, 3111, 4657,  776, 5458, 2924,\n",
      "            0, 6172, 8439, 5358, 2370, 1901, 2227, 2370, 2251, 5182, 1901, 7485,\n",
      "         6722, 6204, 3900, 8391,    0, 1953, 6219, 2251],\n",
      "        [1160, 5294, 6219,  471, 5442, 1901, 5657, 5316, 6214, 6422, 3334, 5294,\n",
      "         3753,  864, 4917, 1953, 1680, 6408, 7564, 5658, 5479, 6591, 6512, 1901,\n",
      "         7461,    1,    1,    1,    1,    1,    1,    1]]), tensor([0, 0])]\n",
      "tensor([[3070, 2750, 3116, 3109, 2750, 2084,  782, 3111, 4657,  776, 5458, 2924,\n",
      "            0, 6172, 8439, 5358, 2370, 1901, 2227, 2370, 2251, 5182, 1901, 7485,\n",
      "         6722, 6204, 3900, 8391,    0, 1953, 6219, 2251],\n",
      "        [1160, 5294, 6219,  471, 5442, 1901, 5657, 5316, 6214, 6422, 3334, 5294,\n",
      "         3753,  864, 4917, 1953, 1680, 6408, 7564, 5658, 5479, 6591, 6512, 1901,\n",
      "         7461,    1,    1,    1,    1,    1,    1,    1]]) tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "mb = next(iter(tr_dl))\n",
    "x_mb, y_mb = mb\n",
    "\n",
    "print(mb)\n",
    "print(x_mb, y_mb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MultiChannelEmbedding`, `ConvolutionLayer`, `MaxOverTimepooling` 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model.ops import MultiChannelEmbedding, ConvolutionLayer, MaxOverTimePooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MultiChannelEmbedding` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Embedding.from_pretrained, torch.Tensor.permute를 이용하여 직접 구현해보세요.\n",
    "# https://github.com/aisolab/strnlp/blob/master/exercise/model/ops.py\n",
    "class MultiChannelEmbedding(nn.Module):\n",
    "    \"\"\"MultiChannelEmbedding class\"\"\"\n",
    "    def __init__(self, vocab: Vocab) -> None:\n",
    "        \"\"\"Instantiating MultiChannelEmbedding class\n",
    "\n",
    "        Args:\n",
    "            vocab (model.utils.Vocab): the instance of model.utils.Vocab\n",
    "        \"\"\"\n",
    "        super(MultiChannelEmbedding, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.2286, -0.2849, -0.5418,  ..., -0.3589, -0.0767,  0.0862],\n",
      "         [ 0.1945, -0.0632,  0.0037,  ...,  0.2641,  0.0233,  0.2906],\n",
      "         [-0.7672, -0.3738, -0.3894,  ..., -0.6365, -0.2963, -0.4155],\n",
      "         ...,\n",
      "         [-0.2776,  0.3091, -0.8164,  ...,  0.2565,  0.2070,  0.0206],\n",
      "         [-0.2625, -0.0234,  0.2058,  ...,  0.1482, -0.0095, -0.3524],\n",
      "         [-0.0459,  0.1627, -0.5181,  ..., -0.0044,  0.1284,  0.5323]],\n",
      "\n",
      "        [[-0.5872, -0.6691, -0.0767,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2138,  0.6100,  0.0233,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.7448, -0.9603, -0.2963,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.2106,  0.3919,  0.2070,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1595, -0.2109, -0.0095,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2779,  0.3197,  0.1284,  ...,  0.0000,  0.0000,  0.0000]]]),\n",
      " tensor([[[-0.2286, -0.2849, -0.5418,  ..., -0.3589, -0.0767,  0.0862],\n",
      "         [ 0.1945, -0.0632,  0.0037,  ...,  0.2641,  0.0233,  0.2906],\n",
      "         [-0.7672, -0.3738, -0.3894,  ..., -0.6365, -0.2963, -0.4155],\n",
      "         ...,\n",
      "         [-0.2776,  0.3091, -0.8164,  ...,  0.2565,  0.2070,  0.0206],\n",
      "         [-0.2625, -0.0234,  0.2058,  ...,  0.1482, -0.0095, -0.3524],\n",
      "         [-0.0459,  0.1627, -0.5181,  ..., -0.0044,  0.1284,  0.5323]],\n",
      "\n",
      "        [[-0.5872, -0.6691, -0.0767,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2138,  0.6100,  0.0233,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.7448, -0.9603, -0.2963,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.2106,  0.3919,  0.2070,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1595, -0.2109, -0.0095,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2779,  0.3197,  0.1284,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<PermuteBackward>))\n"
     ]
    }
   ],
   "source": [
    "ops1 = MultiChannelEmbedding(vocab)\n",
    "h1 = ops1(x_mb)\n",
    "pprint(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 300, 32]) torch.Size([2, 300, 32])\n"
     ]
    }
   ],
   "source": [
    "print(h1[0].shape, h1[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ConvolutionLayer` class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Conv1d, F.relu를 이용하여 직접 구현해보세요.\n",
    "# https://github.com/aisolab/strnlp/blob/master/exercise/model/ops.py\n",
    "class ConvolutionLayer(nn.Module):\n",
    "    \"\"\"ConvolutionLayer class\"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        \"\"\"Instantiating ConvolutionLayer class\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): the number of channels from input feature map\n",
    "            out_channels (int): the number of achannels from output feature map\n",
    "        \"\"\"\n",
    "        super(ConvolutionLayer, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0417, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1638, 0.2253,  ..., 0.1884, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0152, 0.0844,  ..., 0.0000, 0.0404, 0.1249],\n",
      "         [0.0000, 0.1207, 0.0825,  ..., 0.0746, 0.0000, 0.0000],\n",
      "         [0.1338, 0.2159, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0108, 0.0108, 0.0108],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.1776,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.3244,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.3411,  ..., 0.0163, 0.0163, 0.0163],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "       grad_fn=<AddBackward0>),\n",
      " tensor([[[0.0000, 0.0000, 0.6283,  ..., 0.1075, 0.0751, 0.0420],\n",
      "         [0.0000, 0.0000, 0.1336,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0873, 0.0000, 0.0258,  ..., 0.0532, 0.5280, 0.0331],\n",
      "         ...,\n",
      "         [0.6389, 0.0000, 0.2102,  ..., 0.0000, 0.1650, 0.1698],\n",
      "         [0.0000, 0.0000, 0.3367,  ..., 0.0731, 0.0017, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.3769, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.1592, 0.0252,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5212, 0.0000, 0.0000,  ..., 0.0264, 0.0264, 0.0264],\n",
      "         ...,\n",
      "         [0.2236, 0.3934, 0.4152,  ..., 0.0029, 0.0029, 0.0029],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0326, 0.0326, 0.0326],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0055, 0.0055, 0.0055]]],\n",
      "       grad_fn=<AddBackward0>),\n",
      " tensor([[[0.0393, 0.4059, 0.0000,  ..., 0.0058, 0.0000, 0.0671],\n",
      "         [0.2009, 0.3693, 0.1359,  ..., 0.5446, 0.4244, 0.1132],\n",
      "         [0.0000, 0.1527, 0.0000,  ..., 0.0000, 0.0603, 0.0934],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.1225,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3048, 0.3845, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1740, 0.0000, 0.1590,  ..., 0.1350, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.1546, 0.0730, 0.0948,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.3605, 0.0000, 0.4915,  ..., 0.0514, 0.0514, 0.0514],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0153, 0.0153, 0.0153],\n",
      "         ...,\n",
      "         [0.0000, 0.0104, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.3160,  ..., 0.0070, 0.0070, 0.0070],\n",
      "         [0.3051, 0.4371, 0.0000,  ..., 0.0072, 0.0072, 0.0072]]],\n",
      "       grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "ops2 = ConvolutionLayer(300, 300)\n",
    "h2 = ops2(h1)\n",
    "pprint(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 30]) torch.Size([2, 100, 29]) torch.Size([2, 100, 28])\n"
     ]
    }
   ],
   "source": [
    "print(h2[0].shape, h2[1].shape, h2[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MaxOverTimePooling` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cat을 이용하여 직접 구현해보세요.\n",
    "# https://github.com/aisolab/strnlp/blob/master/exercise/model/ops.py\n",
    "class MaxOverTimePooling(nn.Module):\n",
    "    \"\"\"MaxOverTimePooling class\"\"\"\n",
    "    def forward(self, x: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2640, 0.2315, 0.8197, 0.2081, 0.4671, 0.2751, 0.5050, 0.5101, 0.4386,\n",
      "         0.5332, 0.5659, 0.1766, 0.6489, 0.4278, 0.3121, 0.8617, 0.8794, 0.6339,\n",
      "         0.7556, 0.5185, 0.1264, 0.4284, 0.8094, 0.7758, 0.4959, 0.6870, 0.7204,\n",
      "         0.4188, 0.9218, 0.5356, 0.4754, 0.5462, 0.1303, 0.0880, 0.4976, 0.1217,\n",
      "         0.4644, 0.2966, 0.3623, 0.6821, 0.5480, 0.8581, 0.5285, 0.6904, 0.4506,\n",
      "         0.7266, 0.3949, 0.6736, 0.6757, 0.4294, 0.3831, 0.2945, 1.0985, 0.4672,\n",
      "         0.7046, 0.0690, 0.5930, 0.5998, 0.5665, 0.2038, 0.8935, 0.5419, 0.4419,\n",
      "         0.0232, 0.4533, 0.4174, 0.3695, 0.5994, 0.3664, 0.2113, 0.4901, 0.5019,\n",
      "         0.5643, 0.0317, 0.4696, 0.0000, 0.2428, 0.4474, 0.0618, 0.3768, 0.6045,\n",
      "         0.7579, 0.5252, 0.4199, 0.4577, 0.3627, 0.4137, 0.2940, 0.2348, 0.5498,\n",
      "         0.5365, 0.4529, 0.5545, 0.4880, 0.5185, 0.2144, 0.4718, 0.2025, 0.1990,\n",
      "         0.2343, 0.6283, 0.1336, 0.7006, 0.3720, 0.2310, 0.7196, 0.1828, 0.8884,\n",
      "         0.9363, 0.5323, 0.7200, 0.1611, 0.4376, 0.4969, 0.2235, 0.9066, 0.3708,\n",
      "         0.3536, 0.3129, 0.4827, 0.2482, 0.7876, 0.4492, 0.7115, 0.6776, 0.5425,\n",
      "         0.7046, 0.9155, 0.4940, 0.8930, 0.8353, 0.3568, 0.3760, 0.6250, 0.3045,\n",
      "         0.5774, 0.3817, 0.3263, 0.2382, 0.5144, 0.4330, 0.5373, 0.5973, 0.3467,\n",
      "         0.8502, 0.5398, 0.6694, 0.7059, 0.9084, 0.3905, 0.2213, 0.1748, 0.2387,\n",
      "         0.6716, 0.2674, 0.8444, 0.6845, 0.2120, 0.3598, 0.5365, 0.5845, 0.6077,\n",
      "         0.3155, 1.0028, 0.3254, 0.5175, 0.7326, 0.2238, 0.4414, 0.5750, 0.3914,\n",
      "         0.9205, 0.3387, 0.8229, 0.5024, 0.5692, 0.4837, 0.7758, 0.5111, 0.3428,\n",
      "         0.8208, 0.4359, 0.5440, 0.3746, 0.4690, 0.7046, 0.4934, 0.4463, 0.2926,\n",
      "         0.8338, 0.5587, 0.5971, 0.7498, 0.6967, 0.2369, 0.6227, 0.6552, 0.6389,\n",
      "         0.6404, 0.6698, 0.5621, 0.7609, 0.1917, 0.2998, 0.4779, 0.6244, 0.6984,\n",
      "         0.3799, 0.0870, 0.1369, 0.4772, 0.3638, 0.3664, 0.4264, 0.2726, 0.6563,\n",
      "         0.4592, 0.4654, 0.6986, 0.7010, 0.5318, 0.4551, 0.4412, 0.7086, 1.3860,\n",
      "         0.4431, 0.4926, 0.3285, 0.6526, 0.3642, 0.2355, 0.3366, 0.7371, 0.5863,\n",
      "         0.5535, 0.4314, 0.5084, 0.4495, 0.4035, 0.6559, 0.3449, 0.7728, 0.3104,\n",
      "         0.4988, 0.3627, 0.4260, 0.2049, 0.6392, 0.2693, 0.3583, 0.3737, 0.5887,\n",
      "         0.4346, 0.6025, 0.6999, 0.4590, 0.5539, 0.7457, 0.6115, 0.8273, 0.4008,\n",
      "         0.4296, 0.6548, 0.6281, 0.5314, 0.7165, 0.2459, 0.6697, 0.3338, 0.4499,\n",
      "         0.3062, 0.7810, 0.5390, 0.8058, 0.4655, 0.8094, 0.3387, 0.5209, 0.8443,\n",
      "         0.3769, 0.7260, 0.4085, 0.5028, 0.4680, 0.4743, 0.6242, 0.4711, 0.7454,\n",
      "         0.1077, 0.4303, 0.3140, 0.6667, 0.3917, 0.1530, 0.5157, 0.4618, 0.5526,\n",
      "         0.4519, 0.4109, 0.8708],\n",
      "        [0.3365, 0.1137, 0.4555, 0.2526, 0.3698, 0.2948, 0.5498, 0.3121, 0.3259,\n",
      "         0.5130, 0.2553, 0.1116, 0.4926, 0.3208, 0.5015, 0.5852, 0.5627, 0.2926,\n",
      "         0.6234, 0.1908, 0.1659, 0.3378, 0.8022, 0.4542, 0.2861, 0.5988, 0.8077,\n",
      "         0.2481, 0.7039, 0.4757, 0.2217, 0.4995, 0.2371, 0.3918, 0.6196, 0.2571,\n",
      "         0.5889, 0.7158, 0.3371, 0.4991, 0.5741, 0.8733, 0.7660, 0.9243, 0.7941,\n",
      "         0.6378, 0.2561, 0.3223, 0.6775, 0.6781, 0.4123, 0.3530, 0.6329, 0.5178,\n",
      "         0.6543, 0.1240, 0.4335, 0.3000, 0.5788, 0.2385, 0.8190, 0.1559, 0.5772,\n",
      "         0.0148, 0.4386, 0.3391, 0.3690, 0.4582, 0.1909, 0.7076, 0.3230, 0.6655,\n",
      "         0.4522, 0.0462, 0.5681, 0.0936, 0.3941, 0.3113, 0.3130, 0.3752, 0.6334,\n",
      "         0.7374, 0.4496, 0.4283, 0.3122, 0.4600, 0.4228, 0.3145, 0.1035, 0.5265,\n",
      "         0.4946, 0.6515, 0.8757, 0.3464, 0.6479, 0.0378, 0.2792, 0.3244, 0.6005,\n",
      "         0.1668, 0.4145, 0.0000, 0.7057, 0.3803, 0.2087, 0.6155, 0.3721, 0.5644,\n",
      "         0.5294, 0.5823, 0.4385, 0.1442, 0.4398, 0.7010, 0.0837, 0.1375, 0.3919,\n",
      "         0.4468, 0.4092, 0.3288, 0.2250, 0.5010, 0.4238, 0.6615, 0.4427, 0.5334,\n",
      "         0.7788, 0.8720, 0.6862, 0.5746, 0.2492, 0.6188, 0.4914, 0.4881, 0.5508,\n",
      "         0.5870, 0.3151, 0.5723, 0.3491, 0.9418, 0.4467, 0.4293, 0.3881, 0.3192,\n",
      "         0.5009, 0.4001, 0.4191, 0.6822, 0.8701, 0.3290, 0.3150, 0.2152, 0.2033,\n",
      "         0.5165, 0.3000, 0.4451, 0.5366, 0.1201, 0.3697, 0.4931, 0.6164, 0.7232,\n",
      "         0.4238, 0.5182, 0.2515, 0.5802, 0.5505, 0.4053, 0.5249, 0.5564, 0.3665,\n",
      "         1.0409, 0.3048, 0.3514, 0.0000, 0.5897, 0.6154, 0.7162, 0.5238, 0.2722,\n",
      "         1.0277, 0.2356, 0.5606, 0.2020, 0.2513, 0.6010, 0.7150, 0.5215, 0.4269,\n",
      "         0.6000, 0.4437, 0.7692, 0.3302, 0.7741, 0.2100, 0.5254, 0.4814, 0.6687,\n",
      "         0.4950, 0.3960, 0.4854, 0.6139, 0.3730, 0.5709, 0.5368, 0.5417, 0.7010,\n",
      "         0.3661, 0.2598, 0.1763, 0.4461, 0.3862, 0.4078, 0.3662, 0.1577, 0.6310,\n",
      "         0.4713, 0.4638, 0.6528, 0.2955, 0.2161, 0.3251, 0.4249, 0.3240, 0.7026,\n",
      "         0.5481, 0.4047, 0.2431, 0.6804, 0.4218, 0.1417, 0.3313, 0.4307, 0.7947,\n",
      "         0.6331, 0.2234, 0.5599, 0.5715, 0.3635, 0.8103, 0.7360, 0.9664, 0.2979,\n",
      "         0.5011, 0.3660, 0.5890, 0.2160, 0.5925, 0.2124, 0.3241, 0.4441, 0.3748,\n",
      "         0.4376, 0.3968, 0.5529, 0.6474, 0.2267, 0.8022, 1.0089, 0.4784, 0.5481,\n",
      "         0.5510, 0.5533, 0.6385, 0.7353, 0.7320, 0.4792, 0.5202, 0.3727, 0.2372,\n",
      "         0.4259, 0.5567, 0.5735, 0.9359, 0.4238, 0.6252, 0.5042, 0.4895, 0.7364,\n",
      "         0.2956, 0.6940, 0.5128, 0.6751, 0.4003, 0.5403, 0.5438, 0.6464, 0.5184,\n",
      "         0.1643, 0.4853, 0.3724, 0.7772, 0.1852, 0.5225, 0.3781, 0.4004, 0.5640,\n",
      "         0.5402, 0.6449, 0.4662]], grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "ops3 = MaxOverTimePooling()\n",
    "h3 = ops3(h2)\n",
    "pprint(h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 300])\n"
     ]
    }
   ],
   "source": [
    "print(h3.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
